{
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "6fc4d67a333a4af39bbba90a651f9f95": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_594dbfd7d4644c949044437d5de3098d",
       "IPY_MODEL_76fc953b4d4a4fac9e19141c9c914500",
       "IPY_MODEL_6e467df067d04450bc0bbfa86e1dbf82"
      ],
      "layout": "IPY_MODEL_ce2fd02d4240479e82911c3186f141c0"
     }
    },
    "594dbfd7d4644c949044437d5de3098d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_30625311db5f47608542ed177a804af8",
      "placeholder": "​",
      "style": "IPY_MODEL_5b6164b0f4144930981240276426cf69",
      "value": "config.json: 100%"
     }
    },
    "76fc953b4d4a4fac9e19141c9c914500": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_25be80e5e67a45649aa348d3a9bcf074",
      "max": 385,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c96b9f11c5954bfc893ba21ccda69373",
      "value": 385
     }
    },
    "6e467df067d04450bc0bbfa86e1dbf82": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cff918b4a64442b59625ab110782360f",
      "placeholder": "​",
      "style": "IPY_MODEL_5369898ea5fe45378d0f09c1e4746963",
      "value": " 385/385 [00:00&lt;00:00, 18.5kB/s]"
     }
    },
    "ce2fd02d4240479e82911c3186f141c0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30625311db5f47608542ed177a804af8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b6164b0f4144930981240276426cf69": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "25be80e5e67a45649aa348d3a9bcf074": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c96b9f11c5954bfc893ba21ccda69373": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cff918b4a64442b59625ab110782360f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5369898ea5fe45378d0f09c1e4746963": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b5a510e16e784c5f9a5b652d669e3785": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4b81d6afeb0b47178112c40fe3cb12bf",
       "IPY_MODEL_ab7871af07774bf5ae95121c4323ddc3",
       "IPY_MODEL_96c05d00d79642a0920ad75eb9aacb01"
      ],
      "layout": "IPY_MODEL_64da800d87274c97ab5b11a93a768d59"
     }
    },
    "4b81d6afeb0b47178112c40fe3cb12bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4cfdaca6e7a04ddb960bfef93f1c3c80",
      "placeholder": "​",
      "style": "IPY_MODEL_5e15c552069d4d8db549a1f0ecd7d7ca",
      "value": "vocab.txt: 100%"
     }
    },
    "ab7871af07774bf5ae95121c4323ddc3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f93d328739c4ff5941b4f9c01d410f0",
      "max": 410806,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b4faeead0af84928b2295cb222683f15",
      "value": 410806
     }
    },
    "96c05d00d79642a0920ad75eb9aacb01": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_27fa21c6aed847b8a097f51f64b875e0",
      "placeholder": "​",
      "style": "IPY_MODEL_cb010f142d404a29857d6474a64f4883",
      "value": " 411k/411k [00:00&lt;00:00, 9.29MB/s]"
     }
    },
    "64da800d87274c97ab5b11a93a768d59": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4cfdaca6e7a04ddb960bfef93f1c3c80": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5e15c552069d4d8db549a1f0ecd7d7ca": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7f93d328739c4ff5941b4f9c01d410f0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4faeead0af84928b2295cb222683f15": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "27fa21c6aed847b8a097f51f64b875e0": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb010f142d404a29857d6474a64f4883": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 72812,
     "databundleVersionId": 8088273,
     "sourceType": "competition"
    },
    {
     "sourceId": 7980468,
     "sourceType": "datasetVersion",
     "datasetId": 4696967
    }
   ],
   "dockerImageVersionId": 30674,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 0,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AutoModel, AutoTokenizer, AdamW\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import os\n",
    "import random\n",
    "from IPython import display\n",
    "\n",
    "model_url = 'dumitrescustefan/bert-base-romanian-uncased-v1'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device\n"
   ],
   "metadata": {
    "id": "l0MfNvYlvCx1",
    "execution": {
     "iopub.status.busy": "2024-03-30T11:36:42.458372Z",
     "iopub.execute_input": "2024-03-30T11:36:42.458964Z",
     "iopub.status.idle": "2024-03-30T11:36:42.465965Z",
     "shell.execute_reply.started": "2024-03-30T11:36:42.458930Z",
     "shell.execute_reply": "2024-03-30T11:36:42.464994Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6b0365bb-5981-4d8e-c052-4a26f56bab8f",
    "ExecuteTime": {
     "end_time": "2024-03-30T16:17:32.819656Z",
     "start_time": "2024-03-30T16:17:31.461475Z"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def reset_numpy_seed(seed_value=42):\n",
    "  try:\n",
    "    # Set NumPy random seed\n",
    "    import numpy as np\n",
    "    np.random.seed(seed_value)\n",
    "    print(f'NumPy random seed set with value: {seed_value}')\n",
    "  except Exception as e:\n",
    "    print(f'NumPy random seed was not set: {e}')\n",
    "  return\n",
    "\n",
    "\n",
    "def reset_tensorflow_seed(seed_value=42):\n",
    "  try:\n",
    "    # Set TensorFlow random seed\n",
    "    import tensorflow as tf\n",
    "    success = False\n",
    "    # Here we have 2 different ways to set the seed\n",
    "    # depending on the version of TensorFlow\n",
    "    try:\n",
    "      tf.random.set_seed(seed_value)\n",
    "      success = True\n",
    "    except Exception as e:\n",
    "      pass\n",
    "    try:\n",
    "      tf.set_random_seed(seed_value)\n",
    "      success = True\n",
    "    except Exception as e:\n",
    "      pass\n",
    "    if success:\n",
    "      print(f'TensorFlow random seed set with value: {seed_value}')\n",
    "    else:\n",
    "      print(f'TensorFlow random seed was not set')\n",
    "  except Exception as e:\n",
    "    print(f'TensorFlow random seed was not set: {e}')\n",
    "  return\n",
    "\n",
    "\n",
    "def reset_torch_seed(seed_value=42):\n",
    "  try:\n",
    "    # Set PyTorch random seed\n",
    "    import torch\n",
    "    torch.manual_seed(seed_value)\n",
    "    if torch.cuda.is_available():\n",
    "      torch.cuda.manual_seed(seed_value)\n",
    "      torch.cuda.manual_seed_all(seed_value)  # if you are using multiple GPUs\n",
    "    print(f'PyTorch random seed set with value: {seed_value}')\n",
    "  except Exception as e:\n",
    "    print(f'PyTorch random seed was not set: {e}')\n",
    "  return\n",
    "\n",
    "\n",
    "def set_random_seeds(seed_value=42):\n",
    "  # Set Python random seed\n",
    "  random.seed(seed_value)\n",
    "  reset_numpy_seed(seed_value)\n",
    "  reset_tensorflow_seed(seed_value)\n",
    "  reset_torch_seed(seed_value)\n",
    "  return\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  # Set the desired seed value\n",
    "  seed = 42\n",
    "\n",
    "  # Set random seeds\n",
    "  set_random_seeds(seed)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7LFHzss521ho",
    "outputId": "f50f9343-3c6b-47e5-8df5-60211b1d90a1",
    "execution": {
     "iopub.status.busy": "2024-03-30T11:36:42.470909Z",
     "iopub.execute_input": "2024-03-30T11:36:42.471710Z",
     "iopub.status.idle": "2024-03-30T11:36:42.484821Z",
     "shell.execute_reply.started": "2024-03-30T11:36:42.471677Z",
     "shell.execute_reply": "2024-03-30T11:36:42.483763Z"
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "collapsed": true,
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-03-30T16:17:32.826283Z",
     "start_time": "2024-03-30T16:17:32.819656Z"
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy random seed set with value: 42\n",
      "TensorFlow random seed was not set: No module named 'tensorflow'\n",
      "PyTorch random seed set with value: 42\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class DatasetTransformer(Dataset):\n",
    "  def __init__(self, X, y, tokenizer):\n",
    "    self.tokenizer = tokenizer\n",
    "    self.X = X\n",
    "    self.y = y\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.y)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    text = self.X[idx]\n",
    "    label = self.y[idx]\n",
    "\n",
    "    text = text.replace(\"ţ\", \"ț\").replace(\"ş\", \"ș\").replace(\"Ţ\", \"Ț\").replace(\"Ş\", \"Ș\")\n",
    "    text_tensor = self.tokenizer.encode(text, add_special_tokens=True, max_length=512, padding='max_length', return_tensors='pt', truncation=True)\n",
    "\n",
    "    return text_tensor, torch.tensor(label)\n",
    "\n"
   ],
   "metadata": {
    "id": "NDPjWypCxV0U",
    "execution": {
     "iopub.status.busy": "2024-03-30T11:36:42.486668Z",
     "iopub.execute_input": "2024-03-30T11:36:42.487009Z",
     "iopub.status.idle": "2024-03-30T11:36:42.501663Z",
     "shell.execute_reply.started": "2024-03-30T11:36:42.486977Z",
     "shell.execute_reply": "2024-03-30T11:36:42.500771Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-03-30T16:17:32.839396Z",
     "start_time": "2024-03-30T16:17:32.826283Z"
    }
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class TransformerModel(nn.Module):\n",
    "  def __init__(self, in_dim=768, no_classes=2):\n",
    "    super(TransformerModel, self).__init__()\n",
    "\n",
    "    self.transformer = AutoModel.from_pretrained(model_url)\n",
    "    self.fc1 = nn.Linear(in_dim, no_classes)\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = x.squeeze(1)\n",
    "    out = self.transformer(out)[0][:, 0, :]\n",
    "    out = F.dropout(out, p=0.1)\n",
    "    out = self.fc1(out)\n",
    "    return out"
   ],
   "metadata": {
    "id": "qswOHUPRydls",
    "execution": {
     "iopub.status.busy": "2024-03-30T11:36:42.503034Z",
     "iopub.execute_input": "2024-03-30T11:36:42.503851Z",
     "iopub.status.idle": "2024-03-30T11:36:42.517428Z",
     "shell.execute_reply.started": "2024-03-30T11:36:42.503813Z",
     "shell.execute_reply": "2024-03-30T11:36:42.516490Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-03-30T16:17:32.845374Z",
     "start_time": "2024-03-30T16:17:32.839396Z"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_url)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185,
     "referenced_widgets": [
      "6fc4d67a333a4af39bbba90a651f9f95",
      "594dbfd7d4644c949044437d5de3098d",
      "76fc953b4d4a4fac9e19141c9c914500",
      "6e467df067d04450bc0bbfa86e1dbf82",
      "ce2fd02d4240479e82911c3186f141c0",
      "30625311db5f47608542ed177a804af8",
      "5b6164b0f4144930981240276426cf69",
      "25be80e5e67a45649aa348d3a9bcf074",
      "c96b9f11c5954bfc893ba21ccda69373",
      "cff918b4a64442b59625ab110782360f",
      "5369898ea5fe45378d0f09c1e4746963",
      "b5a510e16e784c5f9a5b652d669e3785",
      "4b81d6afeb0b47178112c40fe3cb12bf",
      "ab7871af07774bf5ae95121c4323ddc3",
      "96c05d00d79642a0920ad75eb9aacb01",
      "64da800d87274c97ab5b11a93a768d59",
      "4cfdaca6e7a04ddb960bfef93f1c3c80",
      "5e15c552069d4d8db549a1f0ecd7d7ca",
      "7f93d328739c4ff5941b4f9c01d410f0",
      "b4faeead0af84928b2295cb222683f15",
      "27fa21c6aed847b8a097f51f64b875e0",
      "cb010f142d404a29857d6474a64f4883"
     ]
    },
    "id": "S9z7h_I5ynxC",
    "outputId": "968767ee-197e-4a7e-9f18-3da8e8d1532b",
    "execution": {
     "iopub.status.busy": "2024-03-30T11:36:42.556747Z",
     "iopub.execute_input": "2024-03-30T11:36:42.557051Z",
     "iopub.status.idle": "2024-03-30T11:36:42.826279Z",
     "shell.execute_reply.started": "2024-03-30T11:36:42.557027Z",
     "shell.execute_reply": "2024-03-30T11:36:42.825190Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-03-30T16:17:33.636531Z",
     "start_time": "2024-03-30T16:17:32.845374Z"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def train_epoch(model, optim, loss_fn, dataloader, epoch_idx):\n",
    "    \"\"\" Trains the model for one epoch and returns the loss together with a classification report\n",
    "    \"\"\"\n",
    "\n",
    "    epoch_loss = 0\n",
    "    # Put the model in training mode\n",
    "    model.train()\n",
    "    preds = []\n",
    "    gt = []\n",
    "\n",
    "    for idx, batch in enumerate(dataloader):\n",
    "        # Reset gradients\n",
    "        optim.zero_grad()\n",
    "\n",
    "        inputs, labels = batch\n",
    "        labels = torch.nn.functional.one_hot(labels, num_classes=2).float()\n",
    "\n",
    "        # Move data to GPU\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        output = model(inputs.to(device))\n",
    "        # Calculate the loss and backpropagate\n",
    "        loss = loss_fn(output, labels)\n",
    "        loss.backward()\n",
    "        # Update weights\n",
    "        optim.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        probs = F.softmax(output, dim=-1)\n",
    "        batch_preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "        preds.append(batch_preds.cpu().numpy())\n",
    "        gt.append(labels.cpu().numpy())\n",
    "\n",
    "    # Average the epoch losses\n",
    "    epoch_loss /= len(dataloader)\n",
    "\n",
    "    preds = np.concatenate(preds)\n",
    "    gt = np.concatenate(gt)\n",
    "    gt = np.argmax(gt, axis=1)\n",
    "\n",
    "    # Get an epoch classification report\n",
    "    clf_report = classification_report(gt, preds, output_dict=True)\n",
    "\n",
    "    return epoch_loss, clf_report\n",
    "\n",
    "def test(model, loss_fn, dataloader):\n",
    "\n",
    "    test_loss = 0\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    gt = []\n",
    "\n",
    "    # Tell PyTorch that we won't be computing gradients\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(dataloader):\n",
    "            inputs, labels = batch\n",
    "            labels = torch.nn.functional.one_hot(labels, num_classes=2).float()\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            output = model(inputs)\n",
    "            test_loss += loss_fn(output, labels).item()\n",
    "\n",
    "            probs = F.softmax(output, dim=-1)\n",
    "            batch_preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "            preds.append(batch_preds.cpu().numpy())\n",
    "            gt.append(labels.cpu().numpy())\n",
    "\n",
    "    test_loss /= len(dataloader)\n",
    "    preds = np.concatenate(preds)\n",
    "    gt = np.concatenate(gt)\n",
    "    gt = np.argmax(gt, axis=1)\n",
    "\n",
    "    # Get a classification report\n",
    "    clf_report = classification_report(gt, preds, output_dict=True)\n",
    "    clf_report_text = classification_report(gt, preds)\n",
    "\n",
    "    return test_loss, clf_report, clf_report_text"
   ],
   "metadata": {
    "id": "R_15-ZKN1qxa",
    "execution": {
     "iopub.status.busy": "2024-03-30T11:36:42.828297Z",
     "iopub.execute_input": "2024-03-30T11:36:42.828610Z",
     "iopub.status.idle": "2024-03-30T11:36:42.843902Z",
     "shell.execute_reply.started": "2024-03-30T11:36:42.828582Z",
     "shell.execute_reply": "2024-03-30T11:36:42.842820Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-03-30T16:17:33.641815Z",
     "start_time": "2024-03-30T16:17:33.636531Z"
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_path = 'train.csv'\n",
    "test_path = 'test.csv'"
   ],
   "metadata": {
    "id": "UWQVkhDz3rAf",
    "execution": {
     "iopub.status.busy": "2024-03-30T11:36:42.845089Z",
     "iopub.execute_input": "2024-03-30T11:36:42.847528Z",
     "iopub.status.idle": "2024-03-30T11:36:42.857184Z",
     "shell.execute_reply.started": "2024-03-30T11:36:42.847497Z",
     "shell.execute_reply": "2024-03-30T11:36:42.856313Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-03-30T16:17:33.656574Z",
     "start_time": "2024-03-30T16:17:33.641815Z"
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def preprocess_df(df):\n",
    "    df['title'] = df['title'].fillna('')\n",
    "    df['content'] = df['content'].fillna('')\n",
    "    df[\"title_content\"] = df[\"title\"] + ' ' + df['content']\n",
    "\n",
    "    # Other preprocessing\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-30T11:36:42.858495Z",
     "iopub.execute_input": "2024-03-30T11:36:42.858796Z",
     "iopub.status.idle": "2024-03-30T11:36:42.867240Z",
     "shell.execute_reply.started": "2024-03-30T11:36:42.858770Z",
     "shell.execute_reply": "2024-03-30T11:36:42.866262Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true,
    "id": "SdwBaOhKOIhS",
    "ExecuteTime": {
     "end_time": "2024-03-30T16:17:33.662556Z",
     "start_time": "2024-03-30T16:17:33.656574Z"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Takes the train dataset path and the test dataset path and returns the X and y dataset split into X_train, X_val, X_test, y_train, y_val\n",
    "def train_test_valid(train_path=train_path, test_path=test_path, remove_punctuation=True, seed=42):\n",
    "\n",
    "    df_train = pd.read_csv(train_path)\n",
    "    df_train = preprocess_df(df_train)\n",
    "\n",
    "    df_test = pd.read_csv(test_path)\n",
    "    df_test = preprocess_df(df_test)\n",
    "\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "\n",
    "    # Then we move them to some vectors in memory\n",
    "    for index, sample in df_train.iterrows():\n",
    "        text = sample['title_content']\n",
    "        class_id = sample['class']\n",
    "\n",
    "        if remove_punctuation:\n",
    "            text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "        X_train.append(text)\n",
    "        y_train.append(int(class_id))\n",
    "\n",
    "    for index, sample in df_test.iterrows():\n",
    "        text = sample['title_content']\n",
    "\n",
    "        if remove_punctuation:\n",
    "            text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "        X_test.append(text)\n",
    "\n",
    "\n",
    "    # And we finally split the training data into train/valid\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, stratify=y_train, random_state=seed)\n",
    "    y_test = [0 for _ in range(len(X_test))]\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n"
   ],
   "metadata": {
    "id": "kZbcIj9-2hQT",
    "execution": {
     "iopub.status.busy": "2024-03-30T11:46:27.748448Z",
     "iopub.execute_input": "2024-03-30T11:46:27.748983Z",
     "iopub.status.idle": "2024-03-30T11:46:27.759957Z",
     "shell.execute_reply.started": "2024-03-30T11:46:27.748948Z",
     "shell.execute_reply": "2024-03-30T11:46:27.759039Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-03-30T16:17:33.669077Z",
     "start_time": "2024-03-30T16:17:33.662556Z"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Get the dataset splits once again, this time containing punctuation\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = train_test_valid(remove_punctuation=False)\n",
    "\n",
    "# Train on a smaller ammount of data\n",
    "data_size = 1000\n",
    "X_train = X_train[:data_size]\n",
    "y_train = y_train[:data_size]"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-30T11:36:42.882445Z",
     "iopub.execute_input": "2024-03-30T11:36:42.882868Z",
     "iopub.status.idle": "2024-03-30T11:36:52.694606Z",
     "shell.execute_reply.started": "2024-03-30T11:36:42.882834Z",
     "shell.execute_reply": "2024-03-30T11:36:52.693530Z"
    },
    "trusted": true,
    "id": "v4HLw2AoOIhT",
    "ExecuteTime": {
     "end_time": "2024-03-30T16:17:37.011456Z",
     "start_time": "2024-03-30T16:17:33.670082Z"
    }
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "('Cum şi-a refuzat Comisarul Firinel mântuirea? Închis la şliţ pentru a nu i se vedea „România nor-ma-lă,” noul regim şi-a trimis sculele pe post de cerberi.Astfel nu se explică minunea. Din obermaister al fortăreţei de suflete închise, Marginea dâmboviţeană, comisarul Firinel Ungureanu a ajuns director general al Administraţiei Naţionale a Penitenciarelor. Din înalta postură de cerber al proscrişilor, comisarul a făcut tot ce e cătăneşte posibil să cadă bine în ochii noilor stăpâni. Nu l-au deranjat nici regulamentele, nici drepturile fundamentale ale omului, nici informaţia că Papa n-are divizii de luptă, ci doar ambasadori. Prin cel puţin trei decizii le-a arătat creştinilor că-şi refuză mântuirea. L-a luat pe Liviu Dragnea din regimul special de detenţie şi l-a dus printre cei de drept comun, periclitându-i viaţa, doar pentru a fi pe plac celor care l-au numit. N-are rost să ne mai întrebăm ce e la bază şi ce e la vârf. Băieţii ştiu că nu slobozesc pe fiştecine să fie câine de lagăr. A doua decizie a umilului serv de regim e refuzul vizitei Monseniorului Buendia în celula lui Liviu Dragnea, în calitate de Nunţiu Papal. Profitând de dreptul familiei de a-l vizita, viitorul cardinal a fost strecurat pe lista celor cu acces, maximă umilinţă pentru trimisul papei Francisc. Comisarul Firinel, fără să-şi dea seama, l-a umilit pe însuşi Papa Francisc. A treia decizie: Comisarul Firinel a dispus şi comunicat prin secretară că fapta civilă, de comitere a acţiunii de supunere a deţinutului la un interviu lumesc cu Oana Zamfir pentru difuzarea pe postul Antena 3, în săptămâna când toţi creştinii iartă, e de drept privat, inoportună. În dreptul civil, nu există inoportunitate. Prin încadrarea intenţiei drept inoportună, Comisarul Firinel s-a pus mai presus de lege, de credinţă şi de regulamente. Nimeni nu poate încălca dreptul constituţional al omului, fie deţinut, fie jurnalist, de a-şi exprima opiniile. Poate că fostul şef al PSD vroia să ceară public mântuirea. Cel puţin un lucru e clar: încă nu s-a născut niciun cetăţean european care poate să aresteze ideile. Ele circulă liber şi dincolo de zăbrele, oricâte piedici ar ridica cerberii în calea celui ce trebuie uitat pentru odioasa faptă de a fi mai întâi naţionalist şi apoi europenist. Liviu Dragnea a fost ars simbolic între coloane pentru ca nimeni să nu mai îndrăznească să comită fapta neagreată de Comisiile de la Veneţia de a ţine cu ţara lui. Comisarul Firinel a venit în post cu tot aplombul miliţianului ce ştie că scaunul se ţine, nu se dă.A preferat să-şi refuze mântuirea doar de drag de poziţie, funcţie şi grad. Nu ştie că regimurile cu pastile albastre au scule de unică folosinţă. Poate că în apropiata şi previzibila retragere la vatră va căuta un preot căruia să-i mărturisească cele trei fapte anticreştine. Niciunui criminal nu i se poate refuza mântuirea. Dar dacă Firinel îşi refuză ultimul drept, pentru că aşa i-a cerut gheneralul? Rămâne cu credinţa-n gratii şi cătuşe? Bietul suflet pierdut. Cum şi-a jertifit dreptul divin, pentru nedreptul civil…',\n 1)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0], y_train[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-30T16:17:37.014246Z",
     "start_time": "2024-03-30T16:17:37.011456Z"
    }
   },
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "ds_train = DatasetTransformer(X_train, y_train, tokenizer)\n",
    "ds_val = DatasetTransformer(X_val, y_val, tokenizer)\n",
    "ds_test = DatasetTransformer(X_test, y_test, tokenizer)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    ds_train, sampler=RandomSampler(ds_train), batch_size=BATCH_SIZE, num_workers=16\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    ds_val, sampler=SequentialSampler(ds_val), batch_size=BATCH_SIZE, num_workers=16\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    ds_test, sampler=SequentialSampler(ds_test), batch_size=BATCH_SIZE, num_workers=16\n",
    ")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-30T11:36:52.737131Z",
     "iopub.execute_input": "2024-03-30T11:36:52.737572Z",
     "iopub.status.idle": "2024-03-30T11:36:52.761714Z",
     "shell.execute_reply.started": "2024-03-30T11:36:52.737540Z",
     "shell.execute_reply": "2024-03-30T11:36:52.760589Z"
    },
    "trusted": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RMvrGqjsOIhU",
    "outputId": "78bf8f51-6e40-4008-e5e6-234bfb175169",
    "ExecuteTime": {
     "end_time": "2024-03-30T16:17:37.020603Z",
     "start_time": "2024-03-30T16:17:37.014246Z"
    }
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Instantiate our model and move it to GPU\n",
    "model = TransformerModel().to(device)\n",
    "\n",
    "# Freeze all the Transformer parameters\n",
    "for p in model.transformer.parameters():\n",
    "    p.requires_grad = False\n",
    "# ... except for the bias terms\n",
    "trainable_params_transformer = [p for (n, p) in model.transformer.named_parameters() if \"bias\" in n]\n",
    "for p in trainable_params_transformer:\n",
    "    p.requires_grad = True\n",
    "\n",
    "# We'll train the final layer and the bias terms\n",
    "trainable_params = list(model.fc1.parameters())\n",
    "trainable_params.extend(list(trainable_params_transformer))\n",
    "\n",
    "# Define our loss and optimizer\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "# We'll use AdamW for the Transformer\n",
    "optim = torch.optim.AdamW(trainable_params)\n",
    "\n",
    "no_epochs = 10\n",
    "best_val_loss = 999"
   ],
   "metadata": {
    "id": "sjVLjYiAQO_y",
    "ExecuteTime": {
     "end_time": "2024-03-30T16:17:38.243171Z",
     "start_time": "2024-03-30T16:17:37.020603Z"
    }
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "\n",
    "# use tqdm for a nice progress bar\n",
    "for epoch_idx in tqdm(range(no_epochs)):\n",
    "    # Train the model for one epoch\n",
    "    train_loss, train_report = train_epoch(model, optim, loss_fn, train_dataloader, epoch_idx)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_report['accuracy'])\n",
    "\n",
    "    # Test the model on the validation set\n",
    "    val_loss, val_report, val_report_text = test(model, loss_fn, val_dataloader)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_report['accuracy'])\n",
    "\n",
    "    # Save the model if the validation loss is the best we've seen so far\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "\n",
    "    # Print the results for this epoch\n",
    "    print(f\"Epoch {epoch_idx}\")\n",
    "    print(f\"Train loss: {train_loss}\")\n",
    "    print(f\"Train accuracy: {train_report['accuracy']}\")\n",
    "    print(f\"Validation loss: {val_loss}\")\n",
    "    print(f\"Validation accuracy: {val_report['accuracy']}\")\n",
    "    print(val_report_text)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-30T11:36:53.704844Z",
     "iopub.status.idle": "2024-03-30T11:36:53.705350Z",
     "shell.execute_reply.started": "2024-03-30T11:36:53.705079Z",
     "shell.execute_reply": "2024-03-30T11:36:53.705099Z"
    },
    "trusted": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nUXzznruOIhV",
    "outputId": "5ebcdfd2-9836-48ed-eb20-37d551eb78c7",
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-03-30T16:17:38.243171Z"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_transformer_model.pt'))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def predict(model, data_loader):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    gt = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(data_loader):\n",
    "            inputs, labels = batch\n",
    "            labels = torch.nn.functional.one_hot(labels, num_classes=2).float()\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            output = model(inputs)\n",
    "\n",
    "            probs = F.softmax(output, dim=-1)\n",
    "            batch_preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "            preds.append(batch_preds.cpu().numpy())\n",
    "            gt.append(labels.cpu().numpy())\n",
    "\n",
    "    preds = np.concatenate(preds)\n",
    "    gt = np.concatenate(gt)\n",
    "    gt = np.argmax(gt, axis=1)\n",
    "\n",
    "    return gt, preds"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "gt, preds = predict(model, test_dataloader)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "torch.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "execution_count": null
  }
 ]
}
