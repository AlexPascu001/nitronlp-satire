{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-31T06:59:27.283214Z",
     "start_time": "2024-03-31T06:59:24.740051Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Alex\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import spacy\n",
    "from transformers import pipeline\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from torch import cuda\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "import nltk\n",
    "from transformers import Trainer\n",
    "nltk.download('words')\n",
    "from nltk.corpus import words\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import TrainingArguments\n",
    "from collections import Counter\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import spacy\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T07:00:09.592752Z",
     "start_time": "2024-03-31T07:00:09.591003Z"
    }
   },
   "id": "cd59014e0c4eac99"
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('training_preprocesat.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T05:47:36.052905900Z",
     "start_time": "2024-03-31T05:47:33.993909700Z"
    }
   },
   "id": "d1c5ef4b13862d9d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(df_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.049907Z"
    }
   },
   "id": "b39568f84949f19"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "Embedding(50005, 768)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dumitrescustefan/bert-base-romanian-cased-v1\")\n",
    "added_toks = tokenizer.add_special_tokens({'additional_special_tokens': ['[STAR]', '[HTAG]', '[REP]', '[PROF]', '[EMOJI]']})\n",
    "\n",
    "robert = AutoModel.from_pretrained(\"dumitrescustefan/bert-base-romanian-cased-v1\")\n",
    "robert.resize_token_embeddings(len(tokenizer))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T06:59:32.462431Z",
     "start_time": "2024-03-31T06:59:31.200332Z"
    }
   },
   "id": "97b337e04f2f9d50"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m df_shuffled \u001B[38;5;241m=\u001B[39m \u001B[43mdf_train\u001B[49m\u001B[38;5;241m.\u001B[39msample(frac\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1000\u001B[39m)\n\u001B[0;32m      2\u001B[0m train_ratio \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.8\u001B[39m\n\u001B[0;32m      3\u001B[0m train_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(train_ratio \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mlen\u001B[39m(df_shuffled))\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "df_shuffled = df_train.sample(frac=0.2, random_state=1000)\n",
    "train_ratio = 0.8\n",
    "train_size = int(train_ratio * len(df_shuffled))\n",
    "df_train = df_shuffled[:train_size]\n",
    "df_val = df_shuffled[train_size:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T06:59:37.757479Z",
     "start_time": "2024-03-31T06:59:37.601341Z"
    }
   },
   "id": "9a9e2cabba3f381"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "aux = list(zip(df_train['title'].tolist(), df_train['class'].tolist()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.053906600Z"
    }
   },
   "id": "78cbf2452e573df7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for title, label in tqdm(aux):\n",
    "    input_ids = torch.tensor(tokenizer.encode(title, add_special_tokens=True, max_length=32, padding='max_length', truncation=True, return_tensors=\"np\"))\n",
    "    outputs = robert(input_ids)\n",
    "    mean_pooling = torch.mean(outputs[0], dim = 1).squeeze(0).detach()\n",
    "    X_train.append(mean_pooling)\n",
    "    y_train.append(label)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.056416900Z"
    }
   },
   "id": "82c5cccab152dfb2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T05:47:36.071446700Z",
     "start_time": "2024-03-31T05:47:36.057417900Z"
    }
   },
   "id": "f8d991598a3843f6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_val = []\n",
    "y_val = []\n",
    "aux = list(zip(df_val['title'].tolist(), df_val['class'].tolist()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.058416600Z"
    }
   },
   "id": "f59f5fa242e026ff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "np.save('x_train.npy', X_train)\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('x_val.npy', X_val)\n",
    "np.save('y_val.npy', y_val)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.059416600Z"
    }
   },
   "id": "b9358d44296ee07e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for title, label in tqdm(aux):\n",
    "    input_ids = torch.tensor(tokenizer.encode(title, add_special_tokens=True, max_length=32, padding='max_length', truncation=True, return_tensors=\"np\"))\n",
    "    outputs = robert(input_ids)\n",
    "    mean_pooling = torch.mean(outputs[0], dim = 1).squeeze(0).detach()\n",
    "    X_val.append(mean_pooling)\n",
    "    y_val.append(label)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.061417300Z"
    }
   },
   "id": "48bd253a931a4919"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.062417200Z"
    }
   },
   "id": "97d828ca99fd951d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.063415700Z"
    }
   },
   "id": "16a7c8f2f3ddae14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# AICI INCEPE MODDELUL PENTRU TITLU"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.064419100Z"
    }
   },
   "id": "fb654c78edeb64cd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.065927600Z"
    }
   },
   "id": "fea016328cf5dd37"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.066933100Z"
    }
   },
   "id": "78074fd37c978fda"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return torch.tensor(self.X[index]), torch.tensor(self.y[index])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T06:59:47.581795Z",
     "start_time": "2024-03-31T06:59:47.579856Z"
    }
   },
   "id": "765dc53f030448fb"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9a9e109cbc65e217"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class ClssificationNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClssificationNetwork, self).__init__()\n",
    "        self.linear = nn.Linear(768, 64)\n",
    "        self.fc = nn.Linear(64, 64)\n",
    "        self.bn = nn.BatchNorm1d(64) \n",
    "        self.classifier = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.classifier(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T06:59:48.314538Z",
     "start_time": "2024-03-31T06:59:48.311034Z"
    }
   },
   "id": "10b0f93dd6de8214"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m train_set \u001B[38;5;241m=\u001B[39m CustomDataset(\u001B[43mX_train\u001B[49m, y_train)\n\u001B[0;32m      2\u001B[0m val_set \u001B[38;5;241m=\u001B[39m CustomDataset(X_val, y_val)\n\u001B[0;32m      4\u001B[0m train_loader \u001B[38;5;241m=\u001B[39m DataLoader(train_set, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "train_set = CustomDataset(X_train, y_train)\n",
    "val_set = CustomDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=16)\n",
    "val_loader = DataLoader(val_set, shuffle=True, batch_size=16)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T06:59:51.037956Z",
     "start_time": "2024-03-31T06:59:51.027344Z"
    }
   },
   "id": "4160ea3d5723003c"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def get_training_data():\n",
    "    first = pd.read_csv('first.csv')\n",
    "    first_titles = np.load('training_splits/firsttitle.npy')\n",
    "    first_labels = first['class'].tolist()\n",
    "\n",
    "    second = pd.read_csv('second.csv')\n",
    "    second_titles = np.load('training_splits/secondtitle.npy')\n",
    "    second_labels = second['class'].tolist()\n",
    "\n",
    "    third = pd.read_csv('third.csv')\n",
    "    third_titles = np.load('training_splits/thirdtitle.npy')\n",
    "    third_labels = third['class'].tolist()\n",
    "\n",
    "    fourth = pd.read_csv('fourth.csv')\n",
    "    fourth_titles = np.load('training_splits/fourthtitle.npy')\n",
    "    fourth_labels = fourth['class'].tolist()\n",
    "\n",
    "    all_titles = np.concatenate((first_titles, second_titles, third_titles, fourth_titles), axis=0)\n",
    "    all_labels = np.concatenate((first_labels, second_labels, third_labels, fourth_labels))\n",
    "    return all_titles, all_labels\n",
    "\n",
    "def get_validation_data():\n",
    "    fourth = pd.read_csv('fourth.csv')\n",
    "    fourth_titles = np.load('training_splits/fourthtitle.npy')\n",
    "    fourth_labels = fourth['class'].tolist()\n",
    "    \n",
    "    return fourth_titles, fourth_labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T06:59:53.552436Z",
     "start_time": "2024-03-31T06:59:53.549371Z"
    }
   },
   "id": "d357fda1b63146ac"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "X_train, y_train = get_training_data()\n",
    "# X_val, y_val = get_validation_data()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T06:59:56.297551Z",
     "start_time": "2024-03-31T06:59:54.582231Z"
    }
   },
   "id": "4d2331338017b42d"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train_set = CustomDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=128)\n",
    "\n",
    "# val_set = CustomDataset(X_val, y_val)\n",
    "# val_loader = DataLoader(val_set, shuffle=True, batch_size=16)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T06:59:56.300104Z",
     "start_time": "2024-03-31T06:59:56.297551Z"
    }
   },
   "id": "fd6097f5a0a50558"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "model_titles = ClssificationNetwork().to(device)\n",
    "optimizer = optim.Adam(model_titles.parameters(),lr=1e-4)\n",
    "criterion = nn.BCELoss(weight=torch.tensor([len(y_train) / np.sum(y_train)]).to(device))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T07:00:14.413131Z",
     "start_time": "2024-03-31T07:00:14.277934Z"
    }
   },
   "id": "27959d750cb1fb23"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "EPOCHS = 50"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T07:00:20.497801Z",
     "start_time": "2024-03-31T07:00:20.495788Z"
    }
   },
   "id": "30488759e3e80ea0"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 398.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss 0.003515754671859098  | Train Precision: 0.9035580109285697 | Train Recall: 0.8958046848060617 | Train F1: 0.899365709648426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 454.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Train Loss 0.002039492212838545  | Train Precision: 0.9395799670622464 | Train Recall: 0.9424370055123696 | Train F1: 0.9409765615121961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 495.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Train Loss 0.0016425846306402207  | Train Precision: 0.9470241573977467 | Train Recall: 0.9504716820940008 | Train F1: 0.9487028684309813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 439.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Train Loss 0.001454091458315077  | Train Precision: 0.9512051658783787 | Train Recall: 0.9543775957026193 | Train F1: 0.9527535968723553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 489.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Train Loss 0.001346458756677223  | Train Precision: 0.9545213432533521 | Train Recall: 0.9573840962728517 | Train F1: 0.9559221484867226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 485.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Train Loss 0.0012629954340726598  | Train Precision: 0.9567693668181332 | Train Recall: 0.9595295749280945 | Train F1: 0.9581212109766662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 490.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Train Loss 0.0011999992771337161  | Train Precision: 0.95946606119796 | Train Recall: 0.9620919527333851 | Train F1: 0.9607535990595917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 466.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Train Loss 0.0011330770949628229  | Train Precision: 0.9618830139574308 | Train Recall: 0.963904081426233 | Train F1: 0.962878493208867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 468.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Train Loss 0.0010743096775625465  | Train Precision: 0.9637358899345879 | Train Recall: 0.965815197756264 | Train F1: 0.9647597109846388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 426.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Train Loss 0.0010191260274096995  | Train Precision: 0.9657689170709524 | Train Recall: 0.9678573406184501 | Train F1: 0.9667972572614796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 510.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Train Loss 0.000987464944764829  | Train Precision: 0.9662031276579737 | Train Recall: 0.9684365160864217 | Train F1: 0.9673017271130568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 462.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Train Loss 0.0009453981335760042  | Train Precision: 0.9679209402429692 | Train Recall: 0.9696406119787107 | Train F1: 0.9687700351096593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 461.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Train Loss 0.0009025067593468439  | Train Precision: 0.9687009929203808 | Train Recall: 0.9706422493905655 | Train F1: 0.9696580038684972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 443.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Train Loss 0.0008813036289098804  | Train Precision: 0.9697005356133235 | Train Recall: 0.971351053612042 | Train F1: 0.9705159447196345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 474.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Train Loss 0.0008296103067900909  | Train Precision: 0.9724037824681147 | Train Recall: 0.9743179220779293 | Train F1: 0.9733477549284419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 435.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Train Loss 0.0008029695094306997  | Train Precision: 0.9730209307184849 | Train Recall: 0.974725454665891 | Train F1: 0.9738627990487263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 463.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Train Loss 0.0007678987806215177  | Train Precision: 0.9741978380664933 | Train Recall: 0.9758641594933151 | Train F1: 0.9750210960235941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 432.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Train Loss 0.0007375195849534201  | Train Precision: 0.9751293973039901 | Train Recall: 0.9765444283147116 | Train F1: 0.9758297692395911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 452.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Train Loss 0.0007173020072977728  | Train Precision: 0.9756508969664734 | Train Recall: 0.9774927897105329 | Train F1: 0.9765598221941405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 468.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Train Loss 0.0006846373920619085  | Train Precision: 0.9768416368807022 | Train Recall: 0.9783468136145312 | Train F1: 0.9775861926188965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 500.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 | Train Loss 0.000660526970424527  | Train Precision: 0.9782987376084316 | Train Recall: 0.9799110322401838 | Train F1: 0.9790957201494455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 502.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 | Train Loss 0.0006296447772945075  | Train Precision: 0.9786707136507289 | Train Recall: 0.9803099375104867 | Train F1: 0.9794808656445944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 431.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 | Train Loss 0.0006303424685641313  | Train Precision: 0.9784946043192708 | Train Recall: 0.9801161133476375 | Train F1: 0.9792960954221313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 468.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 | Train Loss 0.0005838050765560181  | Train Precision: 0.9809442435056133 | Train Recall: 0.9822994903342042 | Train F1: 0.9816154215521936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 445.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 | Train Loss 0.0005791750501764027  | Train Precision: 0.9806247112695686 | Train Recall: 0.9823050163057978 | Train F1: 0.9814549858150823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 436.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 | Train Loss 0.0005553983147254228  | Train Precision: 0.9812471566712957 | Train Recall: 0.9828865979825734 | Train F1: 0.9820574864662523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 482.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 | Train Loss 0.000540053598097209  | Train Precision: 0.9822885488677773 | Train Recall: 0.9836389987266926 | Train F1: 0.982957398865726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 434.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 | Train Loss 0.0005244473949395057  | Train Precision: 0.9825250097585478 | Train Recall: 0.9836532045085505 | Train F1: 0.9830846488441298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 464.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 | Train Loss 0.0004864989698254354  | Train Precision: 0.9842616762041944 | Train Recall: 0.9855229051426615 | Train F1: 0.9848867563112165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 433.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 | Train Loss 0.0004967144534705707  | Train Precision: 0.9833248198153408 | Train Recall: 0.9846695689595171 | Train F1: 0.9839908919154139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 424.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31 | Train Loss 0.0004785580342871048  | Train Precision: 0.9845272334534523 | Train Recall: 0.9856601096152269 | Train F1: 0.9850892027641509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 480.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32 | Train Loss 0.0004575464201391458  | Train Precision: 0.9852745997039924 | Train Recall: 0.986271650252493 | Train F1: 0.985769665352622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 434.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33 | Train Loss 0.00043835864850093835  | Train Precision: 0.9854217885794019 | Train Recall: 0.9867982946308655 | Train F1: 0.9861034808341533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 517.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34 | Train Loss 0.0004461668060005821  | Train Precision: 0.9853920645591108 | Train Recall: 0.9865527969127721 | Train F1: 0.9859677529407442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 441.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35 | Train Loss 0.0004064526642836727  | Train Precision: 0.9869955505980069 | Train Recall: 0.98806513039796 | Train F1: 0.9875263826893385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 434.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36 | Train Loss 0.00040902903550600345  | Train Precision: 0.986501616113477 | Train Recall: 0.9877859745849462 | Train F1: 0.9871380951335349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 530.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37 | Train Loss 0.00038722788652211204  | Train Precision: 0.9873913258474347 | Train Recall: 0.9884099808467296 | Train F1: 0.9878970653546579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 441.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38 | Train Loss 0.0003734774668389813  | Train Precision: 0.9883851196296554 | Train Recall: 0.9892676570330522 | Train F1: 0.9888236984821912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 432.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39 | Train Loss 0.00037275305806494416  | Train Precision: 0.9877365402760213 | Train Recall: 0.9887127564190543 | Train F1: 0.9882213546980222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 413.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 | Train Loss 0.00035468267069509055  | Train Precision: 0.9885724509256312 | Train Recall: 0.9899404962565256 | Train F1: 0.9892500515922271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 462.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41 | Train Loss 0.00033499305392387194  | Train Precision: 0.9897207136745172 | Train Recall: 0.9906143166223979 | Train F1: 0.9901647684646462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 440.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42 | Train Loss 0.00033066456009986085  | Train Precision: 0.9893423610596941 | Train Recall: 0.9902525678513127 | Train F1: 0.9897946122001289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 419.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43 | Train Loss 0.0003513257966921551  | Train Precision: 0.9885571871333643 | Train Recall: 0.9895264027098414 | Train F1: 0.9890385558005521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 431.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44 | Train Loss 0.00031341365300731675  | Train Precision: 0.9896875754882806 | Train Recall: 0.9905551670450277 | Train F1: 0.9901187810919418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 459.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45 | Train Loss 0.0003262626325360257  | Train Precision: 0.9892854236663271 | Train Recall: 0.9902474291114842 | Train F1: 0.9897632417381939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 482.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46 | Train Loss 0.0003039754190263819  | Train Precision: 0.9903814185113992 | Train Recall: 0.9909736888970178 | Train F1: 0.9906763449997364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 411.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47 | Train Loss 0.00028824441982479125  | Train Precision: 0.9909341733747077 | Train Recall: 0.9916221482999859 | Train F1: 0.9912765344522443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:01<00:00, 325.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48 | Train Loss 0.00027779832349103344  | Train Precision: 0.9915776314794236 | Train Recall: 0.9924572542229129 | Train F1: 0.9920147952422398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:02<00:00, 231.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49 | Train Loss 0.00028596991769883843  | Train Precision: 0.990905252918659 | Train Recall: 0.9919573305467362 | Train F1: 0.9914275047454417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2081287659.py:10: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.X[index]), torch.tensor(self.y[index])\n",
      "100%|██████████| 552/552 [00:02<00:00, 216.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50 | Train Loss 0.00027392673519321384  | Train Precision: 0.9912940239337573 | Train Recall: 0.9922165442920534 | Train F1: 0.9917523710963201\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    running_loss = 0\n",
    "    running_acc = 0\n",
    "\n",
    "    train_pred_labels = []\n",
    "    train_true_labels = []\n",
    "\n",
    "    for X, y in tqdm(train_loader):\n",
    "        y = y.to(device, dtype=torch.long)\n",
    "        X = X.to(device, dtype=torch.float)\n",
    "\n",
    "        output = model_titles(X)\n",
    "\n",
    "        output.squeeze(1)\n",
    "        pred = output > 0.5\n",
    "\n",
    "        train_pred_labels.extend(pred.cpu().numpy().tolist())\n",
    "        train_true_labels.extend(y.cpu().numpy().tolist())\n",
    "        \n",
    "        loss = criterion(output.squeeze(1), y.float())\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        model_titles.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # pred_labels = []\n",
    "    # true_labels = []\n",
    "    # \n",
    "    # model_titles.eval()\n",
    "    # val_loss = 0\n",
    "    # with torch.no_grad():\n",
    "    #     for X, y in tqdm(val_loader):\n",
    "    #         y = y.to(device, dtype=torch.long)\n",
    "    #         X = X.to(device, dtype=torch.float)\n",
    "    # \n",
    "    #         output = model_titles(X)\n",
    "    #         val_loss += criterion(output.squeeze(1), y.float()).item()\n",
    "    #         output.squeeze(1)\n",
    "    # \n",
    "    #         pred = (output > 0.5)\n",
    "    #         pred_labels.extend(pred.cpu().numpy().tolist())\n",
    "    #         true_labels.extend(y.cpu().numpy().tolist())\n",
    "    # \n",
    "    # model_titles.train()\n",
    "    # \n",
    "    # precision, recall, f1, _ = precision_recall_fscore_support(true_labels, pred_labels, average='macro')\n",
    "    precision_train, recall_train, f1_train, _ = precision_recall_fscore_support(train_pred_labels, train_true_labels, average='macro')\n",
    "\n",
    "    print(f\"Epoch: {epoch + 1} | Train Loss {running_loss / len(train_set)}  | Train Precision: {precision_train} | Train Recall: {recall_train} | Train F1: {f1_train}\")\n",
    "    # print(f\"Epoch: {epoch + 1} | Train Loss {running_loss / len(train_set)}  | Train Precision: {precision_train} | Train Recall: {recall_train} | Train F1: {f1_train} | Val Loss: {val_loss / len(val_set)} | Val Precision: {precision} | Val Recall: {recall} | Val F1: {f1}\")\n",
    "\n",
    "torch.save(model_titles.state_dict(), 'models/titleClassifier.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T07:01:37.163678Z",
     "start_time": "2024-03-31T07:00:30.016322Z"
    }
   },
   "id": "1ef77f2027a518d9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.078956600Z"
    }
   },
   "id": "5219a4955ae69fc5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# GATA MODELULU TITLU\n",
    "# GATA MODELULU TITLU"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.080956200Z"
    }
   },
   "id": "12bc5f549bb2ff15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.081956300Z"
    }
   },
   "id": "8ffd78e85671890c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.082955900Z"
    }
   },
   "id": "89de9860a5ce9179"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test_embedding():\n",
    "    df = pd.read_csv('test_preprocesat.csv')\n",
    "    X = []\n",
    "    \n",
    "    for title in tqdm(df['title']):\n",
    "        input_ids = torch.tensor(tokenizer.encode(title, add_special_tokens=True, max_length=32, padding='max_length', truncation=True, return_tensors=\"np\"))\n",
    "        outputs = robert(input_ids)\n",
    "        mean_pooling = torch.mean(outputs[0], dim = 1).squeeze(0).detach()\n",
    "        X.append(mean_pooling)\n",
    "        \n",
    "    X = np.array(X)\n",
    "    np.save('test_embeddings.npy', X)\n",
    "    return X"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.083954200Z"
    }
   },
   "id": "39f0dce3845cd4ee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# X_test = test_embedding()\n",
    "X_test = np.load('test_embeddings.npy')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.085460900Z"
    }
   },
   "id": "af168e4b2348f5bd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.086469300Z"
    }
   },
   "id": "184d82e3b636eddb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_test = np.load('test_embeddings.npy')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.087977600Z"
    }
   },
   "id": "5733fd996e49c7b7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = ClssificationNetwork().to(device)\n",
    "model.load_state_dict(torch.load('haisavedem.pth'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.088983600Z"
    }
   },
   "id": "669bd5884157ed13"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class CustomTestDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return torch.tensor(self.X[index]), y"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.089983800Z"
    }
   },
   "id": "852c8d06d1f31a08"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.eval()\n",
    "predictions = []\n",
    "indices = []\n",
    "cnt = 0\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(X_test))):\n",
    "        axu = torch.tensor(X_test[i], dtype=torch.float).to(device)\n",
    "        prediction = model(axu) > 0.5\n",
    "        predictions.append(prediction.item())\n",
    "        indices.append(cnt)\n",
    "        cnt += 1\n",
    "model.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.090983500Z"
    }
   },
   "id": "7c620b4ea45dfb4b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(ids)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.091981400Z"
    }
   },
   "id": "8fbb6459bc57c07e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "submisie = pd.DataFrame({'id':indices, 'class':list(map(int, predictions))})\n",
    "submisie.to_csv('submission.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.092981200Z"
    }
   },
   "id": "c33bdaba8f4339ba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.093981Z"
    }
   },
   "id": "7e384df2ad9b0c7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T05:47:36.118016200Z",
     "start_time": "2024-03-31T05:47:36.093981Z"
    }
   },
   "id": "7a3ebe8c20470a36"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.095483300Z"
    }
   },
   "id": "6d873f49f3549480"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# preprocess the data for the model\n",
    "def replace_unwanted_characters(df):\n",
    "    df['content'] = df['content'].fillna('')\n",
    "    df['title'] = df['title'].fillna('')\n",
    "    df['title'] = df['title'].apply(lambda x: x.replace(\"ţ\", \"ț\").replace(\"ş\", \"ș\").replace(\"Ţ\", \"Ț\").replace(\"Ş\", \"Ș\"))\n",
    "    df['content'] = df['content'].apply(lambda x: x.replace(\"ţ\", \"ț\").replace(\"ş\", \"ș\").replace(\"Ţ\", \"Ț\").replace(\"Ş\", \"Ș\"))\n",
    "    return df\n",
    "\n",
    "repeated_characters = [x * 3 for x in \"AĂÂBCDEFGHÎJKLMNOPQRSȘTȚUVWXYZaăâbcdefghîjklmnopqrsștțuvwxyz,.-/';[]-!@#$%^&*()?+\"]\n",
    "repeated_characters.append('iiii')\n",
    "repeated_characters.append('IIII')\n",
    "\n",
    "profanity_list = [\n",
    "    \"muie\",\n",
    "    \"laba\",\n",
    "    \"labă\",\n",
    "    \"pula\",\n",
    "    \"pulă\",\n",
    "    \"pizda\",\n",
    "    \"pizdă\",\n",
    "    \"ce pula\",\n",
    "    \"ce pulă\",\n",
    "    \"ce pizda\",\n",
    "    \"ce pizdă\",\n",
    "    \"caca\",\n",
    "    \"cacat\",\n",
    "    \"căcat\",\n",
    "    \"pipi\",\n",
    "    \"pisat\",\n",
    "    \"pișat\",\n",
    "    \"pishat\",\n",
    "    \"rahat\",\n",
    "    \"kkt\",\n",
    "    \"kk\",\n",
    "    \"plm\",\n",
    "    \"ma fut\",\n",
    "    \"mă fut\",\n",
    "    \"ma cac\",\n",
    "    \"mă cac\",\n",
    "    \"ma pis\",\n",
    "    \"mă pis\",\n",
    "    \"ma pish\",\n",
    "    \"mă pish\",\n",
    "    \"pwla\",\n",
    "    \"pwlă\",\n",
    "    \"p.u.l.a.\",\n",
    "    \"poola\",\n",
    "    \"naiba\",\n",
    "    \"dracu\",\n",
    "    \"draq\",\n",
    "    \"drecu\",\n",
    "    \"naibii\",\n",
    "    \"dracului\",\n",
    "    \"drecului\",\n",
    "    \"drqlui\",\n",
    "    \"coaie\",\n",
    "    \"coae\",\n",
    "    \"sloboz\",\n",
    "    \"lindic\",\n",
    "    \"gaoz\",\n",
    "    \"ochiul maro\",\n",
    "    \"floci\",\n",
    "    \"cur\",\n",
    "    \"futai\",\n",
    "    \"futare\",\n",
    "    \"futere\",\n",
    "    \"popou\",\n",
    "    \"nanau\",\n",
    "    \"pulii\",\n",
    "    \"pulii mele\",\n",
    "    \"coaiele\",\n",
    "    \"coaiele mele\",\n",
    "    \"pulile\",\n",
    "    \"măta\",\n",
    "    \"mata\",\n",
    "    \"mă-tii\",\n",
    "    \"mă-ta\",\n",
    "    \"mă-ti\",\n",
    "]\n",
    "\n",
    "english_words = set(words.words())\n",
    "\n",
    "def normalize_text(df):\n",
    "\n",
    "    df['title'] = df['title'].apply(lambda x : re.sub(r\"<.*?>\", '', x ))\n",
    "    df['content'] = df['content'].apply(lambda x:re.sub(r\"<.*?>\", '', x))\n",
    "\n",
    "    df['title'] = df['title'].apply(lambda x : re.sub(r\"\\.\\.\\.\", '', x ))\n",
    "    df['content'] = df['content'].apply(lambda x:re.sub(r\"\\.\\.\\.\", '', x))\n",
    "\n",
    "    df['title'] = df['title'].apply(lambda x : re.sub(r\"#[\\w+-]+\", '[HTAG]', x ))\n",
    "    df['content'] = df['content'].apply(lambda x:re.sub(r\"#[\\w+-]+\", '[HTAG]', x))\n",
    "\n",
    "    df['title'] = df['title'].apply(lambda x : ' '.join([\"[STAR]\" if \"*\" in word else word for word in x.split()]))\n",
    "    df['content'] = df['content'].apply(lambda x:' '.join([\"[STAR]\" if \"*\" in word else word for word in x.split()]))\n",
    "\n",
    "    df['title'] = df['title'].apply(lambda x : ' '.join([\"[REP]\" if any([rep in word for rep in repeated_characters]) else word for word in x.split()]))\n",
    "    df['content'] = df['content'].apply(lambda x : ' '.join([\"[REP]\" if any([rep in word for rep in repeated_characters]) else word for word in x.split()]))\n",
    "\n",
    "    pattern = r'^[!?\"\\',“”-]*(.*?)[!?\"\\',“”-]*$'\n",
    "    df['title'] = df['title'].apply(lambda x : ' '.join([\"[PROF]\" if re.sub(pattern, r'\\1', word) in profanity_list else word for word in x.split()]))\n",
    "    df['content'] = df['content'].apply(lambda x : ' '.join([\"[PROF]\" if re.sub(pattern, r'\\1', word) in profanity_list else word for word in x.split()]))\n",
    "\n",
    "\n",
    "    emoji_pattern = r\"\"\"\n",
    "                    (?:\n",
    "                      [<>]?\n",
    "                      [:;=8]                     # eyes\n",
    "                      [\\-o\\*\\']?                 # optional nose\n",
    "                      [\\)\\]\\(\\[dDpP/\\:\\}\\{@\\|\\\\] # mouth\n",
    "                      |\n",
    "                      [\\)\\]\\(\\[dDpP/\\:\\}\\{@\\|\\\\] # mouth\n",
    "                      [\\-o\\*\\']?                 # optional nose\n",
    "                      [:;=8]                     # eyes\n",
    "                      [<>]?\n",
    "                      |\n",
    "                      </?3                       # heart\n",
    "                    )\"\"\"\n",
    "    df['title'] = df['title'].apply(lambda x : re.sub(emoji_pattern, '[EMOJI]', x ))\n",
    "    df['content'] = df['content'].apply(lambda x : re.sub(emoji_pattern, '[EMOJI]', x ))\n",
    "\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.096485700Z"
    }
   },
   "id": "8c2dd5441fec9d95"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def split_train_in_four(dataset):\n",
    "    length = int(len(dataset) / 4)\n",
    "    \n",
    "    first = dataset[:length]\n",
    "    second = dataset[length:2*length]\n",
    "    third = dataset[2*length:3*length]\n",
    "    fourth = dataset[3*length:4*length]\n",
    "\n",
    "    first.to_csv('first.csv', encoding='utf-8', index=False)\n",
    "    second.to_csv('second.csv', encoding='utf-8', index=False)\n",
    "    third.to_csv('third.csv', encoding='utf-8', index=False)\n",
    "    fourth.to_csv('fourth.csv', encoding='utf-8', index=False)\n",
    "    \n",
    "split_train_in_four(pd.read_csv('data/train.csv'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.097488100Z"
    }
   },
   "id": "835228fffe3097f8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_titles_tokens(df):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    aux = list(zip(df['title'].tolist(), df['class'].tolist()))\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"dumitrescustefan/bert-base-romanian-cased-v1\")\n",
    "    added_toks = tokenizer.add_special_tokens({'additional_special_tokens': ['[STAR]', '[HTAG]', '[REP]', '[PROF]', '[EMOJI]']})\n",
    "    \n",
    "    robert = AutoModel.from_pretrained(\"dumitrescustefan/bert-base-romanian-cased-v1\")\n",
    "    robert.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    for title, label in tqdm(aux):\n",
    "        input_ids = torch.tensor(tokenizer.encode(title, add_special_tokens=True, max_length=32, padding='max_length', truncation=True, return_tensors=\"np\"))\n",
    "        outputs = robert(input_ids)\n",
    "        mean_pooling = torch.mean(outputs[0], dim = 1).squeeze(0).detach()\n",
    "        X_train.append(mean_pooling)\n",
    "        y_train.append(label)\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    \n",
    "    return X_train, y_train\n",
    "\n",
    "def get_content_tokens(df):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    aux = list(zip(df['content'].tolist(), df['class'].tolist()))\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"dumitrescustefan/bert-base-romanian-cased-v1\")\n",
    "    added_toks = tokenizer.add_special_tokens({'additional_special_tokens': ['[STAR]', '[HTAG]', '[REP]', '[PROF]', '[EMOJI]']})\n",
    "    \n",
    "    robert = AutoModel.from_pretrained(\"dumitrescustefan/bert-base-romanian-cased-v1\")\n",
    "    robert.resize_token_embeddings(len(tokenizer))\n",
    "        \n",
    "    for content, label in tqdm(aux):\n",
    "        if len(content) > 0:\n",
    "            input_ids = torch.tensor(tokenizer.encode(content, add_special_tokens=True, max_length=512, padding='max_length', truncation=True, return_tensors=\"np\"))\n",
    "            outputs = robert(input_ids)\n",
    "            mean_pooling = torch.mean(outputs[0], dim = 1).squeeze(0).detach()\n",
    "            X_train.append(mean_pooling)\n",
    "            y_train.append(label)\n",
    "        else:\n",
    "            X_train.append([0 for _ in range(768)])\n",
    "            y_train.append(label)\n",
    "    \n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "\n",
    "    return X_train, y_train\n",
    "\n",
    "\n",
    "def preprocess_dataset(df, name):\n",
    "    df = replace_unwanted_characters(df)\n",
    "    df = normalize_text(df)\n",
    "    \n",
    "    text_embeddings, _ = get_titles_tokens(df)\n",
    "    content_embeddings, _ = get_content_tokens(df)\n",
    "    \n",
    "    np.save(name+'title.npy', text_embeddings)\n",
    "    np.save(name+'content.npy', content_embeddings)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.097488100Z"
    }
   },
   "id": "e8f4be5ee12d6560"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('fourth.csv')\n",
    "preprocess_dataset(df, 'fourth')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.098486Z"
    }
   },
   "id": "e29d17c1aadde196"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.099486Z"
    }
   },
   "id": "9f80c916d8cb317d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# AICI ESTE MODELUL PENTRU TITLU SI CONTENT"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.100485800Z"
    }
   },
   "id": "be64bd58fb40bcc7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.101485800Z"
    }
   },
   "id": "7463eb085f22c2cb"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "class TitleAndContent(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TitleAndContent, self).__init__()\n",
    "        self.linear_text = nn.Linear(768, 128)\n",
    "        self.linear_content = nn.Linear(768, 128)\n",
    "        self.linear_histogram = nn.Linear(18, 64)\n",
    "        self.fc = nn.Linear(256 + 64, 256)\n",
    "        self.bn = nn.BatchNorm1d(256)\n",
    "        self.classifier = nn.Linear(256, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, titles, contents, histograms):\n",
    "        titles = self.linear_text(titles)\n",
    "        contents = self.linear_content(contents)\n",
    "        histograms = self.linear_histogram(histograms)\n",
    "\n",
    "        titles = self.relu(titles)\n",
    "        contents = self.relu(contents)\n",
    "        histograms = self.relu(histograms)\n",
    "\n",
    "        cat = torch.cat([titles, contents, histograms], dim=1)\n",
    "\n",
    "        out = self.fc(cat)\n",
    "        out = self.bn(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.classifier(out)\n",
    "\n",
    "        return self.sigmoid(out)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T07:01:37.169783Z",
     "start_time": "2024-03-31T07:01:37.164681Z"
    }
   },
   "id": "4474e7a91e8895a4"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "class TextAndContentDataset(Dataset):\n",
    "    def __init__(self, x_titles, x_contents, x_hist, y):\n",
    "        super(TextAndContentDataset, self).__init__()\n",
    "        self.x_titles = x_titles\n",
    "        self.x_contents = x_contents\n",
    "        self.x_hist = x_hist\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T07:01:37.188296Z",
     "start_time": "2024-03-31T07:01:37.170871Z"
    }
   },
   "id": "7ec2ad38bf878851"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def get_training_data_content():\n",
    "    first = pd.read_csv('first.csv')\n",
    "    first_indices = first[first['content'].str.len() > 1].index.tolist()\n",
    "    first_titles = np.load('training_splits/firsttitle.npy')\n",
    "    first_titles = first_titles[first_indices]\n",
    "    first_contents = np.load('training_splits/firstcontent.npy')\n",
    "    first_contents = first_contents[first_indices]\n",
    "    first_labels = np.array(first['class'].tolist())\n",
    "    first_labels = first_labels[first_indices]\n",
    "\n",
    "    second = pd.read_csv('second.csv')\n",
    "    second_indices = second[second['content'].str.len() > 1].index.tolist()\n",
    "    second_titles = np.load('training_splits/secondtitle.npy')\n",
    "    second_titles = second_titles[second_indices]\n",
    "    second_contents = np.load('training_splits/secondcontent.npy')\n",
    "    second_contents = second_contents[second_indices]\n",
    "    second_labels = np.array(second['class'].tolist())\n",
    "    second_labels = second_labels[second_indices]\n",
    "\n",
    "    third = pd.read_csv('third.csv')\n",
    "    third_indices = third[third['content'].str.len() > 1].index.tolist()\n",
    "    third_titles = np.load('training_splits/thirdtitle.npy')\n",
    "    third_titles = third_titles[third_indices]\n",
    "    third_contents = np.load('training_splits/thirdcontent.npy')\n",
    "    third_contents = third_contents[third_indices]\n",
    "    third_labels = np.array(third['class'].tolist())\n",
    "    third_labels = third_labels[third_indices]\n",
    "\n",
    "    fourth = pd.read_csv('fourth.csv')\n",
    "    fourth_indices = fourth[fourth['content'].str.len() > 1].index.tolist()\n",
    "    fourth_titles = np.load('training_splits/fourthtitle.npy')\n",
    "    fourth_titles = fourth_titles[fourth_indices]\n",
    "    fourth_contens = np.load('training_splits/fourthcontent.npy')\n",
    "    fourth_contens = fourth_contens[fourth_indices]\n",
    "    fourth_labels = np.array(fourth['class'].tolist())\n",
    "    fourth_labels = fourth_labels[fourth_indices]\n",
    "\n",
    "    histograms = np.load('training_histograms.npy')\n",
    "\n",
    "    all_titles = np.concatenate((first_titles, second_titles, third_titles, fourth_titles), axis=0)\n",
    "    all_contents = np.concatenate((first_contents, second_contents, third_contents, fourth_contens), axis=0)\n",
    "    all_labels = np.concatenate((first_labels, second_labels, third_labels, fourth_labels))\n",
    "    return all_titles, all_contents, all_labels, histograms\n",
    "\n",
    "def get_validation_data_content():\n",
    "    fourth = pd.read_csv('fourth.csv')\n",
    "    fourth_indices = fourth[fourth['content'].str.len() > 1].index.tolist()\n",
    "    fourth_titles = np.load('training_splits/fourthtitle.npy')\n",
    "    fourth_titles = fourth_titles[fourth_indices]\n",
    "    fourth_contens = np.load('training_splits/fourthcontent.npy')\n",
    "    fourth_contens = fourth_contens[fourth_indices]\n",
    "    fourth_labels = np.array(fourth['class'].tolist())\n",
    "    fourth_labels = fourth_labels[fourth_indices]\n",
    "\n",
    "    return fourth_titles, fourth_contens, fourth_labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T07:01:37.197311Z",
     "start_time": "2024-03-31T07:01:37.189299Z"
    }
   },
   "id": "33dd020a34a5c05a"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T07:01:37.201320Z",
     "start_time": "2024-03-31T07:01:37.198316Z"
    }
   },
   "id": "2a3cad5393cb97b0"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "X_train_titles, X_train_contents, y_train , X_train_hist= get_training_data_content()\n",
    "# X_val_titles, X_val_contents, y_val = get_validation_data_content()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T07:02:52.220897Z",
     "start_time": "2024-03-31T07:02:50.390844Z"
    }
   },
   "id": "700df277ae9032aa"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "(69139, 18)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_hist.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T07:02:52.223406Z",
     "start_time": "2024-03-31T07:02:52.220897Z"
    }
   },
   "id": "b628de661e21ca6"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "train_set = TextAndContentDataset(X_train_titles, X_train_contents,X_train_hist, y_train)\n",
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=2048)\n",
    "\n",
    "# val_set = TextAndContentDataset(X_val_titles, X_val_contents,y_val)\n",
    "# val_loader = DataLoader(val_set, shuffle=True, batch_size=16)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T07:11:09.692729Z",
     "start_time": "2024-03-31T07:11:09.689939Z"
    }
   },
   "id": "4910e8b5aa40fdad"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "model_text_and_content = TitleAndContent().to(device)\n",
    "optimizer = optim.Adam(model_text_and_content.parameters(),lr=1e-4)\n",
    "criterion = nn.BCELoss(weight=torch.tensor([len(y_train) / np.sum(y_train)]).to(device))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T07:11:09.907392Z",
     "start_time": "2024-03-31T07:11:09.901878Z"
    }
   },
   "id": "1b29109b5eedb23b"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "EPOCHS = 40"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T07:11:10.104746Z",
     "start_time": "2024-03-31T07:11:10.102591Z"
    }
   },
   "id": "7c34908399d6da7d"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:01<00:00, 20.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss 0.00029485829060716615  | Train Precision: 0.8631395968847366 | Train Recall: 0.8366460433078468 | Train F1: 0.8373539660349287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:01<00:00, 21.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Train Loss 0.00012831705381192423  | Train Precision: 0.9632127482805068 | Train Recall: 0.9591557740407921 | Train F1: 0.9611136741348572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:01<00:00, 23.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Train Loss 9.069340275520804e-05  | Train Precision: 0.9707539549609536 | Train Recall: 0.9701638065070145 | Train F1: 0.9704574954375849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:01<00:00, 22.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 | Train Loss 7.472655205049606e-05  | Train Precision: 0.9759871464342462 | Train Recall: 0.9764020122639757 | Train F1: 0.9761939149259291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:01<00:00, 22.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 | Train Loss 6.45716700921026e-05  | Train Precision: 0.9790097794601154 | Train Recall: 0.9795341789200458 | Train F1: 0.9792709287711321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:01<00:00, 23.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 | Train Loss 5.7182932784231246e-05  | Train Precision: 0.981325106896057 | Train Recall: 0.9820591592972945 | Train F1: 0.9816900947874116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:01<00:00, 22.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7 | Train Loss 5.1336003339413386e-05  | Train Precision: 0.9832965720048163 | Train Recall: 0.9839670026908672 | Train F1: 0.9836300955245411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:01<00:00, 23.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8 | Train Loss 4.653711817267178e-05  | Train Precision: 0.9843675784894832 | Train Recall: 0.9851146231029263 | Train F1: 0.9847390089784636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:01<00:00, 22.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9 | Train Loss 4.30499969726634e-05  | Train Precision: 0.9854527185749775 | Train Recall: 0.9861261402750516 | Train F1: 0.9857877333637133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:01<00:00, 23.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Train Loss 3.94610703177707e-05  | Train Precision: 0.9861146420630607 | Train Recall: 0.9868392375926172 | Train F1: 0.9864749813485731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:01<00:00, 26.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11 | Train Loss 3.6740973867688075e-05  | Train Precision: 0.9868277814357151 | Train Recall: 0.9877804442638156 | Train F1: 0.9873007447025968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:01<00:00, 26.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12 | Train Loss 3.427905567228325e-05  | Train Precision: 0.9879014686490839 | Train Recall: 0.9885866910513131 | Train F1: 0.9882423366687779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:02<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13 | Train Loss 3.254695399324876e-05  | Train Precision: 0.9880549445481347 | Train Recall: 0.9889003278828945 | Train F1: 0.9884749896930364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:03<00:00,  9.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14 | Train Loss 2.967014107435038e-05  | Train Precision: 0.9892765315098216 | Train Recall: 0.9902424526144511 | Train F1: 0.9897560547485985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:03<00:00,  8.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15 | Train Loss 2.7987935848222015e-05  | Train Precision: 0.9897281441248846 | Train Recall: 0.9905426021560482 | Train F1: 0.9901329276580426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:03<00:00,  9.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16 | Train Loss 2.6201362359740343e-05  | Train Precision: 0.990588882675197 | Train Recall: 0.991370908113195 | Train F1: 0.9909776454739436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:03<00:00,  9.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17 | Train Loss 2.4312502829354963e-05  | Train Precision: 0.991347318272364 | Train Recall: 0.9920204550234735 | Train F1: 0.9916822209530813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:03<00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18 | Train Loss 2.3561614520073598e-05  | Train Precision: 0.9918444418052683 | Train Recall: 0.9924928551450833 | Train F1: 0.9921671046175425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:03<00:00,  9.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19 | Train Loss 2.2061348687344417e-05  | Train Precision: 0.992142664398612 | Train Recall: 0.9926645312678244 | Train F1: 0.9924025969860805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:03<00:00,  9.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20 | Train Loss 2.0282348957161913e-05  | Train Precision: 0.9929494633969855 | Train Recall: 0.9935145387585975 | Train F1: 0.9932308310394994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:03<00:00,  9.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21 | Train Loss 1.9042387272144422e-05  | Train Precision: 0.9933301503759173 | Train Recall: 0.99394656404313 | Train F1: 0.9936369673776488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:03<00:00,  8.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22 | Train Loss 1.783882195784783e-05  | Train Precision: 0.9939750019024767 | Train Recall: 0.9945837235984405 | Train F1: 0.9942780097738518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:04<00:00,  8.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23 | Train Loss 1.6839069858955527e-05  | Train Precision: 0.9944095854946815 | Train Recall: 0.9948998948402681 | Train F1: 0.99465386211615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:03<00:00,  9.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24 | Train Loss 1.62031684466115e-05  | Train Precision: 0.9943215449583609 | Train Recall: 0.9948627070855733 | Train F1: 0.9945910568286664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:03<00:00,  8.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25 | Train Loss 1.5257431332774597e-05  | Train Precision: 0.9947703909673904 | Train Recall: 0.9953205463547863 | Train F1: 0.9950443651944947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:04<00:00,  8.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26 | Train Loss 1.3971360882253206e-05  | Train Precision: 0.9955089450583346 | Train Recall: 0.9959578253113857 | Train F1: 0.995732651179543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:03<00:00,  8.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27 | Train Loss 1.2805865802951941e-05  | Train Precision: 0.9962135269808944 | Train Recall: 0.9968164721683219 | Train F1: 0.9965136805791366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:03<00:00,  9.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28 | Train Loss 1.2242847979646387e-05  | Train Precision: 0.9962646140494684 | Train Recall: 0.996765283448459 | Train F1: 0.9965140381998481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:03<00:00,  9.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29 | Train Loss 1.1516627244559931e-05  | Train Precision: 0.9968071196842168 | Train Recall: 0.9971294625061773 | Train F1: 0.9969679133759191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:03<00:00,  8.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30 | Train Loss 1.0826138604291816e-05  | Train Precision: 0.9970542981476522 | Train Recall: 0.9974449157012002 | Train F1: 0.9972490531384626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:03<00:00,  9.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31 | Train Loss 9.93050429025987e-06  | Train Precision: 0.997309948183851 | Train Recall: 0.9976581643361367 | Train F1: 0.9974836162552815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:03<00:00,  8.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32 | Train Loss 9.436714490955349e-06  | Train Precision: 0.9977104737303399 | Train Recall: 0.998007845751699 | Train F1: 0.9978588390046935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:03<00:00,  8.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33 | Train Loss 8.790587847528634e-06  | Train Precision: 0.9977843377271675 | Train Recall: 0.998090272926778 | Train F1: 0.9979369659624857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:03<00:00,  8.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34 | Train Loss 8.08631902512312e-06  | Train Precision: 0.998233183736197 | Train Recall: 0.9985479227149233 | Train F1: 0.9983901945514297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:03<00:00,  9.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35 | Train Loss 8.034994901696536e-06  | Train Precision: 0.9981422477778457 | Train Recall: 0.9983887518030502 | Train F1: 0.9982652795252429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:03<00:00,  8.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36 | Train Loss 7.1763906823382816e-06  | Train Precision: 0.9985314492682065 | Train Recall: 0.9988122517244655 | Train F1: 0.9986715651177069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:03<00:00,  8.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37 | Train Loss 6.9408601785095455e-06  | Train Precision: 0.9986081228097331 | Train Recall: 0.9988292865952488 | Train F1: 0.9987185275736358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:03<00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38 | Train Loss 6.243098813637805e-06  | Train Precision: 0.9988297148002159 | Train Recall: 0.9990765590161771 | Train F1: 0.9989529164701917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:03<00:00,  8.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39 | Train Loss 5.923395694505696e-06  | Train Precision: 0.9990057958728571 | Train Recall: 0.9991504270233822 | Train F1: 0.9990780357085048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34 [00:00<?, ?it/s]C:\\Users\\Alex\\AppData\\Local\\Temp\\ipykernel_11296\\2085392579.py:13: DeprecationWarning: In future, it will be an error for 'np.bool_' scalars to be interpreted as an index\n",
      "  return torch.tensor(self.x_titles[item]), torch.tensor(self.x_contents[item]), torch.tensor(self.x_hist[item]), torch.tensor(self.y[item])\n",
      "100%|██████████| 34/34 [00:03<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40 | Train Loss 5.42647661713444e-06  | Train Precision: 0.9990512638520328 | Train Recall: 0.9992299922488117 | Train F1: 0.9991405124559314\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    running_loss = 0\n",
    "    running_acc = 0\n",
    "\n",
    "    train_pred_labels = []\n",
    "    train_true_labels = []\n",
    "\n",
    "    for X_title, X_content,X_hist, y in tqdm(train_loader):\n",
    "        y = y.to(device, dtype=torch.long)\n",
    "        X_title = X_title.to(device, dtype=torch.float)\n",
    "        X_hist = X_hist.to(device, dtype=torch.float)\n",
    "        X_content = X_content.to(device, dtype=torch.float)\n",
    "\n",
    "        output = model_text_and_content(X_title, X_content, X_hist)\n",
    "\n",
    "        output.squeeze(1)\n",
    "        pred = output > 0.5\n",
    "\n",
    "        train_pred_labels.extend(pred.cpu().numpy().tolist())\n",
    "        train_true_labels.extend(y.cpu().numpy().tolist())\n",
    "\n",
    "        loss = criterion(output.squeeze(1), y.float())\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        model_text_and_content.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # pred_labels = []\n",
    "    # true_labels = []\n",
    "    # \n",
    "    # model_text_and_content.eval()\n",
    "    # val_loss = 0\n",
    "    # with torch.no_grad():\n",
    "    #     for X_title, X_content, y in tqdm(val_loader):\n",
    "    #         y = y.to(device, dtype=torch.long)\n",
    "    #         X_title = X_title.to(device, dtype=torch.float)\n",
    "    #         X_content = X_content.to(device, dtype=torch.float)\n",
    "    # \n",
    "    #         output = model_text_and_content(X_title, X_content)\n",
    "    #         val_loss += criterion(output.squeeze(1), y.float()).item()\n",
    "    #         output.squeeze(1)\n",
    "    # \n",
    "    #         pred = (output > 0.5)\n",
    "    #         pred_labels.extend(pred.cpu().numpy().tolist())\n",
    "    #         true_labels.extend(y.cpu().numpy().tolist())\n",
    "    # \n",
    "    # model_text_and_content.train()\n",
    "    # \n",
    "    # precision, recall, f1, _ = precision_recall_fscore_support(true_labels, pred_labels, average='macro')\n",
    "    precision_train, recall_train, f1_train, _ = precision_recall_fscore_support(train_pred_labels, train_true_labels, average='macro')\n",
    "\n",
    "\n",
    "    # print(f\"Epoch: {epoch + 1} | Train Loss {running_loss / len(train_set)}  | Train Precision: {precision_train} | Train Recall: {recall_train} | Train F1: {f1_train} | Val Loss: {val_loss / len(val_set)} | Val Precision: {precision} | Val Recall: {recall} | Val F1: {f1}\")\n",
    "    print(f\"Epoch: {epoch + 1} | Train Loss {running_loss / len(train_set)}  | Train Precision: {precision_train} | Train Recall: {recall_train} | Train F1: {f1_train}\")\n",
    "\n",
    "torch.save(model_text_and_content.state_dict(), 'models/titleAndContentClassifier.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T07:13:16.871408Z",
     "start_time": "2024-03-31T07:11:10.252644Z"
    }
   },
   "id": "59b0f7358eb95a03"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "# AICI SE TERMINA MODELUL PENTRU TITLU SI CONTENT\n",
    "# DE AICI INCEPE PENTRU SUBMISIE"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T07:13:16.874767Z",
     "start_time": "2024-03-31T07:13:16.872416Z"
    }
   },
   "id": "53db5b6b0a42d412"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "def get_all_test_data():\n",
    "    file_names = ['first', 'second', 'third', 'fourth', 'fifth', 'sixth']\n",
    "    \n",
    "    all_titles = np.array([])\n",
    "    all_contents = np.array([])\n",
    "    \n",
    "    for f in file_names:\n",
    "        titles = np.load(f'testing_splits/{f}_testtitle.npy')\n",
    "        content = np.load(f'testing_splits/{f}_testcontent.npy')\n",
    "        if len(all_titles) == 0:\n",
    "            all_titles = titles\n",
    "            all_contents = content\n",
    "        else:\n",
    "            all_titles = np.concatenate((all_titles, titles), axis=0)\n",
    "            all_contents = np.concatenate((all_contents, content), axis=0)\n",
    "            \n",
    "    return all_titles, all_contents"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T07:13:16.886459Z",
     "start_time": "2024-03-31T07:13:16.875768Z"
    }
   },
   "id": "2ca713c7ecdebd5a"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "X, y = get_all_test_data()\n",
    "df = pd.read_csv('test.csv')\n",
    "testing_hist = np.load('testing_histograms.npy')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T07:13:18.133357Z",
     "start_time": "2024-03-31T07:13:16.887464Z"
    }
   },
   "id": "2f04baa51a76dd94"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36669/36669 [00:23<00:00, 1540.84it/s]\n"
     ]
    }
   ],
   "source": [
    "all_pred = []\n",
    "ids = []\n",
    "\n",
    "# model_titles = ClssificationNetwork().to(device)\n",
    "# model_titles.load_state_dict(torch.load('haisavedem.pth'))\n",
    "\n",
    "model_titles.eval()\n",
    "model_text_and_content.eval()\n",
    "\n",
    "indices = df[df['content'].str.len() > 1].index.tolist()\n",
    "cnt = 0\n",
    "for i in tqdm(range(len(df))):\n",
    "    title = X[i]\n",
    "    content = y[i]\n",
    "    if i in indices:\n",
    "        title = torch.tensor(title, dtype=torch.float).to(device).unsqueeze(0)\n",
    "        content = torch.tensor(content, dtype=torch.float).to(device).unsqueeze(0)\n",
    "        hist = torch.tensor(testing_hist[cnt], dtype=torch.float).to(device).unsqueeze(0)\n",
    "        cnt += 1\n",
    "        output = model_text_and_content(title, content, hist)\n",
    "        output.squeeze(1)\n",
    "        pred = (output > 0.5).item()\n",
    "    else:\n",
    "        title = torch.tensor(title, dtype=torch.float).to(device).unsqueeze(0)\n",
    "        output = model_titles(title)\n",
    "        output.squeeze(1)\n",
    "        pred = (output > 0.5).item()\n",
    "        \n",
    "    all_pred.append(pred)\n",
    "    ids.append(i)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T07:13:41.947720Z",
     "start_time": "2024-03-31T07:13:18.133357Z"
    }
   },
   "id": "aa2cabb8199d8566"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "submisie = pd.DataFrame({'id':ids, 'class':list(map(int, all_pred))})\n",
    "submisie.to_csv('submission_embeddings_hist_batch_norm_20epochs_2048batch.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T07:13:41.966415Z",
     "start_time": "2024-03-31T07:13:41.947720Z"
    }
   },
   "id": "d34112a4938b7666"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# GATAAAAAAAAAAAA"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.112500400Z"
    }
   },
   "id": "1c1e0651cbf4a999"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_titles_tokens(df):\n",
    "    X_train = []\n",
    "    aux = df['title'].tolist()\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"dumitrescustefan/bert-base-romanian-cased-v1\")\n",
    "    added_toks = tokenizer.add_special_tokens({'additional_special_tokens': ['[STAR]', '[HTAG]', '[REP]', '[PROF]', '[EMOJI]']})\n",
    "\n",
    "    robert = AutoModel.from_pretrained(\"dumitrescustefan/bert-base-romanian-cased-v1\")\n",
    "    robert.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    for title in tqdm(aux):\n",
    "        input_ids = torch.tensor(tokenizer.encode(title, add_special_tokens=True, max_length=32, padding='max_length', truncation=True, return_tensors=\"np\"))\n",
    "        outputs = robert(input_ids)\n",
    "        mean_pooling = torch.mean(outputs[0], dim = 1).squeeze(0).detach()\n",
    "        X_train.append(mean_pooling)\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "\n",
    "    return X_train\n",
    "\n",
    "def get_content_tokens(df):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    aux = df['content'].tolist()\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"dumitrescustefan/bert-base-romanian-cased-v1\")\n",
    "    added_toks = tokenizer.add_special_tokens({'additional_special_tokens': ['[STAR]', '[HTAG]', '[REP]', '[PROF]', '[EMOJI]']})\n",
    "\n",
    "    robert = AutoModel.from_pretrained(\"dumitrescustefan/bert-base-romanian-cased-v1\")\n",
    "    robert.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    for content in tqdm(aux):\n",
    "        if len(content) > 0:\n",
    "            input_ids = torch.tensor(tokenizer.encode(content, add_special_tokens=True, max_length=512, padding='max_length', truncation=True, return_tensors=\"np\"))\n",
    "            outputs = robert(input_ids)\n",
    "            mean_pooling = torch.mean(outputs[0], dim = 1).squeeze(0).detach()\n",
    "            X_train.append(mean_pooling)\n",
    "        else:\n",
    "            X_train.append([0 for _ in range(768)])\n",
    "\n",
    "    X_train = np.array(X_train)\n",
    "\n",
    "    return X_train\n",
    "\n",
    "\n",
    "def preprocess_dataset(df, name):\n",
    "    df = replace_unwanted_characters(df)\n",
    "    df = normalize_text(df)\n",
    "\n",
    "    text_embeddings = get_titles_tokens(df)\n",
    "    content_embeddings = get_content_tokens(df)\n",
    "\n",
    "    np.save(name+'title.npy', text_embeddings)\n",
    "    np.save(name+'content.npy', content_embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.113499200Z"
    }
   },
   "id": "5b0e5cefde7074cf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('first_test.csv')\n",
    "preprocess_dataset(test_df, 'first_test')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.114502800Z"
    }
   },
   "id": "c26fbf0fb8291b60"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('sixth_test.csv')\n",
    "preprocess_dataset(test_df, 'sixth_test')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.114502800Z"
    }
   },
   "id": "e764303c429dc8e4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-03-31T05:47:36.116011700Z"
    }
   },
   "id": "d96354e4c46bf081"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
